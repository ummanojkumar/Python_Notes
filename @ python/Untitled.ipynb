{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,c,mat=int(input()),0,[]\n",
    "for p in range(n):\n",
    "    m=[]\n",
    "    for q in range(n):\n",
    "        c=c+1\n",
    "        m.append(c)\n",
    "    mat.append(m)\n",
    "for r in mat[:-1]:\n",
    "   print(*r)\n",
    "print(*mat[-1],end=\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[]\n",
    "mat=[]\n",
    "for i in range(3):\n",
    "    #for j in range(3):\n",
    "        m.append(input().split())\n",
    "   # mat.append(m)\n",
    "for i in m[:-1]:\n",
    "    print(*i)\n",
    "print(*m[-1],end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "while True:\n",
    "        sentence=str(input(\"say...\"))\n",
    "        translator=Translator()\n",
    "        translated_sentence=translator.translate(sentence,src='en',dest='hi')\n",
    "        print(translated_sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Google Cloud Speech API sample application using the streaming API.\n",
    "NOTE: This module requires the additional dependency `pyaudio`. To install\n",
    "using pip:\n",
    "    pip install pyaudio\n",
    "Example usage:\n",
    "    python transcribe_streaming_mic.py\n",
    "\"\"\"\n",
    "\n",
    "# [START import_libraries]\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import re\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from google.cloud import translate_v2 as translate\n",
    "from google.cloud import speech_v1 as speech\n",
    "from google.cloud.speech_v1 import enums\n",
    "from google.cloud.speech_v1 import types\n",
    "from six.moves import queue\n",
    "# [END import_libraries]\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "\n",
    "# Instantiates a client\n",
    "translate_client = translate.Client()\n",
    "\n",
    "raw_input_data = 'listening...'\n",
    "previous_raw_input_data = None\n",
    "translated_data = None\n",
    "\n",
    "\n",
    "class MicrophoneStream(object):\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "    \n",
    "    def __init__(self, rate, chunk):\n",
    "        \n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        \n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1, rate=self._rate,\n",
    "            input=True, frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        \n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        \n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "    \n",
    "    def _clear_buffer(self):\n",
    "        \n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        # self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def generator(self):\n",
    "\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b''.join(data)\n",
    "# [END audio_stream]\n",
    "\n",
    "def initial_video():\n",
    "\n",
    "    import cv2\n",
    "    \n",
    "    # Inital text translation\n",
    "    text_translation()\n",
    "\n",
    "    # Start microphone stream threading\n",
    "    threading.Thread(target=main).start()\n",
    "\n",
    "    # Set camera device\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    # Set camera width\n",
    "    camera.set(3,1200)\n",
    "    # Set camera height\n",
    "    camera.set(4,1200)\n",
    "\n",
    "    # Set font\n",
    "    fontpath = \"Kanit-Regular.ttf\"\n",
    "    font = ImageFont.truetype(fontpath, 32)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = camera.read()\n",
    "        if ret:\n",
    "            if translated_data:\n",
    "                # Draw background of text\n",
    "                cv2.rectangle(frame, (0, 0), (1400, 40), (0,0,0), -1)\n",
    "                cv2.rectangle(frame, (70, 515), (1200, 545), (0,0,0), -1)                    \n",
    "                cv2.rectangle(frame, (70, 555), (1200, 585), (0,0,0), -1)\n",
    "                cv2.rectangle(frame, (70, 595), (1200, 625), (0,0,0), -1)\n",
    "                cv2.rectangle(frame, (70, 635), (1200, 665), (0,0,0), -1) \n",
    "\n",
    "                # Set draw text frame\n",
    "                img_pil = Image.fromarray(frame)\n",
    "                draw = ImageDraw.Draw(img_pil)\n",
    "\n",
    "                # Write microphone input\n",
    "                draw.text((100, 505), \"Microphone: \" + raw_input_data, font=font, fill=(255,255,255,0))\n",
    "                # Write Thai text\n",
    "                draw.text((75, 545),  \"TH: \" + translated_data['th'], font=font, fill=(255,255,255,0))\n",
    "                # Write English text\n",
    "                draw.text((75, 585),  \"EN: \" + translated_data['en'], font=font, fill=(255,255,255,0))\n",
    "                # Write Deutsch text     \n",
    "                draw.text((75, 625),  \"DE: \" + translated_data['de'], font=font, fill=(255,255,255,0))\n",
    "                # Write demo word text\n",
    "                draw.text((20, -5),  \"Demo\", font=font, fill=(255,255,255,0))\n",
    "                # Write timestamp\n",
    "                draw.text((910, -5), time.strftime(\"%Y/%m/%d %H:%M:%S %Z\", time.localtime()), font=font, fill=(255,255,255,0))   \n",
    "                # Write all text into frame\n",
    "                frame = np.array(img_pil)\n",
    "                # Draw green circle\n",
    "                frame = cv2.circle(frame, (85, 530), 6, (0,255,0), -1)\n",
    "               \n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('Speech-to-Text Demo', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def text_translation(input_text=\"Hello\"):\n",
    "\n",
    "    # Translates text input to English\n",
    "    translation_en = translate_client.translate(input_text, target_language='en')\n",
    "    # Translates text input to Deutsch\n",
    "    translation_de = translate_client.translate(translation_en['translatedText'], target_language='de')\n",
    "\n",
    "    print(u'Text input: {}'.format(input_text))\n",
    "    print(u'Translation to english: {}'.format(translation_en['translatedText']))\n",
    "    print(u'Translation to deutsch: {}'.format(translation_de['translatedText']))\n",
    "\n",
    "    # Set global variable\n",
    "    global translated_data\n",
    "    global previous_raw_input_data\n",
    "    translated_data = {'th': input_text, 'en': translation_en['translatedText'].replace(\"&#39;\", \"'\"), 'de': translation_de['translatedText'].replace(\"&#39;\", \"'\")}\n",
    "    previous_raw_input_data = input_text\n",
    " \n",
    "def listen_print_loop(responses):\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "    \"\"\"\n",
    "\n",
    "    num_chars_printed = 0\n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        # The `results` list is consecutive. For streaming, we only care about\n",
    "        # the first result being considered, since once it's `is_final`, it\n",
    "        # moves on to considering the next utterance.\n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        # Display the transcription of the top alternative.\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        print('Microphone input: ' + transcript)\n",
    "\n",
    "        # Assign raw input\n",
    "        global raw_input_data\n",
    "        raw_input_data = transcript\n",
    "\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "        #\n",
    "        # If the previous result was longer than this one, we need to print\n",
    "        # some extra spaces to overwrite the previous result\n",
    "        overwrite_chars = ' ' * (num_chars_printed - len(transcript))\n",
    "\n",
    "        # if len(raw_input_data) >= 15:\n",
    "        #     sys.stdout.write(transcript + overwrite_chars + '\\r')\n",
    "        #     sys.stdout.flush()\n",
    "\n",
    "        #     num_chars_printed = len(transcript)\n",
    "\n",
    "        #     print('Send to translate !')\n",
    "\n",
    "        #     text_translation(transcript + overwrite_chars)\n",
    "\n",
    "        ########################\n",
    "        #      NEW VERSION     #\n",
    "        ########################\n",
    "        print(result.stability)\n",
    "        if result.stability >= 0.899:\n",
    "            responses = transcript + overwrite_chars\n",
    "            text_translation(responses)\n",
    "            MicrophoneStream(RATE, CHUNK)._clear_buffer()\n",
    "        else:\n",
    "            sys.stdout.write(transcript + overwrite_chars + '\\r')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            num_chars_printed = len(transcript)\n",
    "\n",
    "        ########################\n",
    "        #      OLD VERSION     #\n",
    "        ########################\n",
    "        # if not result.is_final:\n",
    "        #     sys.stdout.write(transcript + overwrite_chars + '\\r')\n",
    "        #     sys.stdout.flush()\n",
    "\n",
    "        #     num_chars_printed = len(transcript)\n",
    "\n",
    "        # else:\n",
    "        #     print(transcript + overwrite_chars)\n",
    "        #     resp = transcript + overwrite_chars\n",
    "        #     text_translation(resp)\n",
    "\n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r'\\b(exit|quit)\\b', transcript, re.I):\n",
    "                print('Exiting..')\n",
    "                break\n",
    "\n",
    "def main():\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    # The language code you speak.\n",
    "    language_code = 'th-TH'  # a BCP-47 language tag\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code)\n",
    "    streaming_config = types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True)\n",
    "\n",
    "    # Initial loop value\n",
    "    rounds = 1\n",
    "    while True:\n",
    "        try:\n",
    "            print('streaming loop :' + str(rounds))\n",
    "            with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "                audio_generator = stream.generator()\n",
    "                # Create request data\n",
    "                requests = (types.StreamingRecognizeRequest(audio_content=content) for content in audio_generator)\n",
    "                # POST data to google cloud speech\n",
    "                responses = client.streaming_recognize(streaming_config, requests)\n",
    "                # Now, put the transcription responses to use.\n",
    "                listen_print_loop(responses)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            rounds += 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    initial_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number: 23\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "a=int(input(\"Enter the number: \"))\n",
    "if a>=90:\n",
    "    print(\"first class\")\n",
    "elif a>=50:\n",
    "    print(\"pass\")\n",
    "elif a>=30:\n",
    "    print(\"just pass\")\n",
    "else:\n",
    "    print(\"fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
